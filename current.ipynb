{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.4.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (3.20.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (0.15.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (2.10.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (0.38.4)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.19.5)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (2.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (2.11.2)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (65.6.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.31.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.4.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (5.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (6.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.4->tensorflow==2.4.1) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.2)\n",
      "Installing collected packages: flatbuffers\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 24.3.25\n",
      "    Uninstalling flatbuffers-24.3.25:\n",
      "      Successfully uninstalled flatbuffers-24.3.25\n",
      "Successfully installed flatbuffers-1.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.9.0.1 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow==2.4.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (0.9.0.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from opencv-python) (1.19.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from mediapipe) (0.15.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from attrs>=19.1.0->mediapipe) (6.7.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (from importlib-metadata->attrs>=19.1.0->mediapipe) (3.15.0)\n",
      "Installing collected packages: flatbuffers\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "Successfully installed flatbuffers-24.3.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires flatbuffers~=1.12.0, but you have flatbuffers 24.3.25 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python mediapipe scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flatbuffers in c:\\users\\khade\\anaconda3\\envs\\gold\\lib\\site-packages (24.3.25)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 1.12.0 (from versions: none)\n",
      "ERROR: No matching distribution found for 1.12.0\n"
     ]
    }
   ],
   "source": [
    "%pip install flatbuffers 1.12.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform detection using MediaPipe Holistic\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert image to RGB\n",
    "    image.flags.writeable = False  # Make image read-only to improve performance\n",
    "    results = model.process(image)  # Perform detection\n",
    "    image.flags.writeable = True  # Make image writable again\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert image back to BGR\n",
    "    return image, results\n",
    "\n",
    "# Function to draw landmarks on the image\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)  # Draw face landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)  # Draw pose landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)  # Draw left hand landmarks\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)  # Draw right hand landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw styled landmarks on the image\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face landmarks with specific styling\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "\n",
    "    # Draw pose landmarks with specific styling\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "\n",
    "    # Draw left hand landmarks with specific styling\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "\n",
    "    # Draw right hand landmarks with specific styling\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('/Users/khade/OneDrive/Documents/UWI-Documents/Year3/Sem2/COMP3901/Final Project/MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "#actions= np.array(['Are you hungry','Do you have any pets'])\n",
    "#actions = np.array(['How are you','Where is the library','My favorite color is green','What is your favorite color',\n",
    " #                   \"No, I don't have any pets\",'Yes I could go for a snack'])\n",
    "\n",
    "actions = np.array(['Are you hungry','Do you have any pets','How are you','Where is the library','My favorite color is green','What is your favorite color',\n",
    "                    \"No, I don't have any pets\",'Yes I could go for a snack'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 15\n",
    "\n",
    "# collect 15 frames from each video\n",
    "sequence_length = 20\n",
    "\n",
    "# Folder start\n",
    "start_folder = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(20,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/khade/OneDrive/Documents/UWI-Documents/Year3/Sem2/COMP3901/Final Project/weights/dense/1501.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite color\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# 1. New detection variables\n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.6\n",
    "frame_count = 0\n",
    "frame_interval = 3  # Adjust this value based on your preference\n",
    "\n",
    "desired_aspect_ratio = 16 / 9\n",
    "desired_width = 1280\n",
    "desired_height = int(desired_width * (9/16))  # Maintain 16:9 aspect ratio\n",
    "\n",
    "\n",
    "# Set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.6, min_tracking_confidence=0.6) as holistic:\n",
    "    # Create a named window with a specific size\n",
    "    cv2.namedWindow('OpenCV Feed', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('OpenCV Feed', desired_width, desired_height)\n",
    "\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        #print(results)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Increment frame count\n",
    "        frame_count += 1\n",
    "\n",
    "        # 2. Prediction logic after processing a certain number of frames\n",
    "        if frame_count % frame_interval == 0:\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "            sequence = sequence[-20:]\n",
    "\n",
    "            if len(sequence) == 20:\n",
    "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                print(actions[np.argmax(res)])\n",
    "                predictions.append(np.argmax(res))\n",
    "                \n",
    "                \n",
    "                # Display predicted text in a box at the top of the screen\n",
    "                #cv2.rectangle(image, (0, 0), (image.shape[1], 50), (0, 0, 0), -1)  # Draw black rectangle\n",
    "                #cv2.putText(image, actions[np.argmax(res)], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "                if np.unique(predictions[-10:])[0]==np.argmax(res):\n",
    "                    if res[np.argmax(res)] > threshold:\n",
    "\n",
    "                        if len(sentence) > 0:\n",
    "                            if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                if len(sentence) > 5:\n",
    "                    sentence = sentence[-5:]\n",
    "\n",
    "                # Print predicted text\n",
    "                #predicted_text = ' '.join(sentence)\n",
    "                #print(\"Translation: \", predicted_text)\n",
    "\n",
    "\n",
    "\n",
    "                # End the loop after making a prediction\n",
    "                break\n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, actions[np.argmax(res)] , (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
